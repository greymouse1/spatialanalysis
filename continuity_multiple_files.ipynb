{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "https://github.com/greymouse1/spatialanalysis/blob/main/continuity_multiple_files.ipynb",
      "authorship_tag": "ABX9TyNtu1WjujfSWEOowdOaAGl9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greymouse1/spatialanalysis/blob/main/continuity_multiple_files.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code is licenced under MIT licence.\n",
        "\n",
        "Author: Nikola G.\n",
        "\n",
        "Credits:\n",
        "\n",
        "Tutorial from Momepy package website at http://docs.momepy.org/en/stable/user_guide/graph/coins.html\n",
        "based on paper by Tripathy et al. (2020)\n",
        "\n",
        "OpenAI. (2024). ChatGPT (version 4) [Large language model]. OpenAI. https://openai.com/chatgpt\n",
        "\n",
        "\n",
        "\n",
        "Tripathy, P., Rao, P., Balakrishnan, K., & Malladi, T. (2020). An open-source tool to extract natural continuity and hierarchy of urban street networks. Environment and Planning B: Urban Analytics and City Science. http://dx.doi.org/10.1177/2399808320967680"
      ],
      "metadata": {
        "id": "D9-uae52ZshA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5Gs0eOwbHEqN"
      },
      "outputs": [],
      "source": [
        "!pip install osmnx > /dev/null 2>&1\n",
        "!pip install momepy > /dev/null 2>&1\n",
        "!pip install mapclassify>=2.4.0 > /dev/null 2>&1 # install mapclassify with version >=2.4.0\n",
        "!pip install powerlaw > /dev/null 2>&1\n",
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "import momepy\n",
        "import mapclassify\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import powerlaw\n",
        "from collections import defaultdict, Counter\n",
        "from shapely.geometry import MultiLineString, LineString, Point"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def naturalCities(currentCity,folderPath,cityName):\n",
        "  # Retrieve the graph within the polygon's boundaries\n",
        "  # This will pull OSM data from inside the polygon and create a networkX graph\n",
        "\n",
        "  graph = ox.graph_from_polygon(\n",
        "      currentCity,\n",
        "      network_type='drive',  # Choose network type (e.g., 'drive', 'walk', 'bike', etc.)\n",
        "      simplify=True,         # Simplify graph (remove unnecessary nodes)\n",
        "      retain_all=False,      # Keep only the largest connected component\n",
        "      truncate_by_edge=False  # Truncate by edge to keep nodes near the edge\n",
        "  )\n",
        "\n",
        "  # Reproject graph\n",
        "  # Choice of final projection is automatic, original must be WGS84\n",
        "\n",
        "  city_streets = ox.projection.project_graph(graph)\n",
        "\n",
        "  # Create gdf from graph so it can be used later on\n",
        "\n",
        "  city_gdf = ox.graph_to_gdfs(\n",
        "      ox.convert.to_undirected(city_streets),\n",
        "      nodes=False,\n",
        "      edges=True,\n",
        "      node_geometry=False,\n",
        "      fill_edge_geometry=True,\n",
        "  )\n",
        "\n",
        "  # Calculate continuity from the gdf\n",
        "\n",
        "  continuity = momepy.COINS(city_gdf, angle_threshold=135, flow_mode=False)\n",
        "\n",
        "  # Pull out stroke\n",
        "\n",
        "  city_stroke_gdf = continuity.stroke_gdf()\n",
        "\n",
        "  # Save stroke to .shp\n",
        "  shapefile_path = os.path.join(folderPath, f\"polygon_{cityName}.shp\")\n",
        "  city_stroke_gdf.to_file(shapefile_path)\n",
        "#--------------------------------------------------------------------------------------------------------------\n",
        "  # Initialize the vertex-to-linestring mapping\n",
        "  vertex_to_linestring = defaultdict(list)\n",
        "\n",
        "  # Iterate over geometries and map vertices to LineStrings (handle MultiLineString)\n",
        "  for idx, geom in city_stroke_gdf.geometry.items():\n",
        "      if isinstance(geom, LineString):  # Process single LineString\n",
        "          for point in geom.coords:\n",
        "              vertex_to_linestring[Point(point)].append(idx)\n",
        "      elif isinstance(geom, MultiLineString):  # Process MultiLineString\n",
        "          # For each LineString in MultiLineString\n",
        "          for subline in geom.geoms:\n",
        "              for point in subline.coords:\n",
        "                  vertex_to_linestring[Point(point)].append(idx)\n",
        "\n",
        "  # Initialize a dictionary to store the connection counts for each line\n",
        "  line_connections = defaultdict(int)\n",
        "\n",
        "  # Iterate over the geometries again to count connections\n",
        "  for idx, geom in city_stroke_gdf.geometry.items():\n",
        "      if isinstance(geom, LineString):  # Process single LineString\n",
        "          connections = []  # Use a list to count multiple connections\n",
        "          for point in geom.coords:\n",
        "              for connected_line in vertex_to_linestring[Point(point)]:\n",
        "                  if connected_line != idx:\n",
        "                      connections.append(connected_line)  # Add connection to the list\n",
        "          line_connections[idx] = len(connections)  # Store the total number of connections\n",
        "      elif isinstance(geom, MultiLineString):  # Process MultiLineString\n",
        "          # For each LineString in MultiLineString\n",
        "          for subline in geom.geoms:\n",
        "              connections = []  # Use a list to count multiple connections for each subline\n",
        "              for point in subline.coords:\n",
        "                  for connected_line in vertex_to_linestring[Point(point)]:\n",
        "                      if connected_line != idx:\n",
        "                          connections.append(connected_line)  # Add connection to the list\n",
        "              # Store the connection count for each subline (if necessary)\n",
        "              # For now, we store the count for the entire MultiLineString\n",
        "              line_connections[idx] = len(connections)\n",
        "\n",
        "\n",
        "  # Extract degree (number of connections) values\n",
        "  degree_values = list(line_connections.values())\n",
        "\n",
        "  # Count frequencies of degree values\n",
        "  degree_counts = Counter(degree_values)\n",
        "\n",
        "  # Extract x (degrees) and y (frequencies)\n",
        "  x = np.array(list(degree_counts.keys()))       # Unique degree values\n",
        "  y = np.array(list(degree_counts.values()))    # Frequency of each degree\n",
        "\n",
        "  # Fit the degree distribution to a power-law model\n",
        "  fit = powerlaw.Fit(degree_values)\n",
        "  print(f\"Alpha: {fit.alpha}\")\n",
        "  print(f\"xmin: {fit.xmin}\")\n",
        "\n",
        "  # Get alpha and xmin (scaling parameter and lower bound for the power-law fit)\n",
        "  alpha = fit.alpha\n",
        "  xmin = fit.xmin\n",
        "\n",
        "  # Get the p-value from the goodness-of-fit test\n",
        "  p_value = fit.power_law.KS()\n",
        "\n",
        "  print(f\"p-value: {p_value}\")\n",
        "  print(\"-----------------------\")\n",
        "  # Compare the power-law fit with an alternative distribution (e.g., exponential)\n",
        "  R, p_alt = fit.distribution_compare('power_law', 'exponential')\n",
        "  print(f\"Log-likelihood ratio (R): {R}\")\n",
        "  print(f\"p-value for comparison: {p_alt}\")\n",
        "\n",
        "  # Plot the data and the fitted power law\n",
        "  fig = fit.plot_pdf(marker='o', color='blue', markersize=4, label='Empirical Data')\n",
        "  fit.power_law.plot_pdf(ax=fig, color='red', linestyle='--', linewidth=1, label='Power Law Fit')\n",
        "\n",
        "  # Add legend and labels\n",
        "  plt.xlabel(\"Degree (Connections)\")\n",
        "  plt.ylabel(\"Frequency\")\n",
        "  plt.legend()\n",
        "\n",
        "  output_path_power = os.path.join(folderPath, f\"power_{cityName}.png\")\n",
        "  plt.savefig(output_path_power, dpi=600, bbox_inches=\"tight\")\n",
        "\n",
        "  print(f\"Plot for power fit for {cityName} saved to {output_path_power}\")\n",
        "  plt.clf() # clear existing plot and make space for a new one\n",
        "\n",
        "#-------------------------\n",
        "  # Add connections to original gdf\n",
        "  city_stroke_gdf['n_connections'] = degree_values\n",
        "\n",
        "  # Calculate heavy tailed classification\n",
        "  classifier = mapclassify.HeadTailBreaks(degree_values)\n",
        "\n",
        "  # Get classification details\n",
        "  class_intervals = classifier.bins  # Class boundaries\n",
        "  counts = classifier.counts         # Number of features in each class\n",
        "  labels = classifier.yb             # Class labels for each feature\n",
        "\n",
        "  # Save classification output to a text file\n",
        "  classifier_path = os.path.join(folderPath, f\"map_classifier_output_{cityName}.txt\")\n",
        "\n",
        "  with open(classifier_path, \"w\") as file:\n",
        "      file.write(\"HeadTailBreaks Classification\\n\")\n",
        "      file.write(\"================================\\n\")\n",
        "      file.write(\"Total segments:\\n\")\n",
        "      file.write(f\"{len(degree_values)}\" + \"\\n\\n\")\n",
        "      file.write(\"HT index of street connectivity:\\n\")\n",
        "      file.write(f\"{len(class_intervals)}\" + \"\\n\\n\")\n",
        "      file.write(\"Class Intervals:\\n\")\n",
        "      file.write(\", \".join(f\"{b:.2f}\" for b in class_intervals) + \"\\n\\n\")\n",
        "      file.write(\"Counts in Each Class:\\n\")\n",
        "      file.write(\", \".join(str(c) for c in counts) + \"\\n\\n\")\n",
        "      file.write(\"Statistical indicators for power law:\" + \"\\n\\n\")\n",
        "      file.write(\"Alpha: \" + str(alpha) + \"\\n\")\n",
        "      file.write(\"xmin: \" + str(xmin) + \"\\n\")\n",
        "      file.write(\"p-value: \" + str(p_value) + \"\\n\")\n",
        "      file.write(\"Log-likelihood ratio (R): \" + str(R) + \"\\n\")\n",
        "      file.write(\"p-value for comparison: \" + str(p_alt) + \"\\n\")\n",
        "\n",
        "\n",
        "  print(f\"Classifier output saved to {classifier_path}\")\n",
        "\n",
        "  # Show the classifier (lower and upper bounds plus count)\n",
        "  print(classifier)\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(15, 15))\n",
        "\n",
        "  city_stroke_gdf.plot(\n",
        "      cmap=\"gist_rainbow\",\n",
        "      column=\"n_connections\",\n",
        "      legend=True,\n",
        "      scheme=\"headtailbreaks\",\n",
        "      linewidth=0.5,\n",
        "      ax=ax,\n",
        "  ).set_axis_off()\n",
        "\n",
        "  fig.patch.set_facecolor(\"black\")\n",
        "\n",
        "  output_path_figure = os.path.join(folderPath, f\"figure_{cityName}.png\")\n",
        "  plt.savefig(output_path_figure, dpi=600, bbox_inches=\"tight\")\n",
        "  plt.close(fig)\n",
        "  print(f\"Plot for {cityName} saved to {output_path_figure}\")\n",
        "\n",
        "  # Histogram for n_segments\n",
        "\n",
        "  city_stroke_gdf['n_connections'].plot(kind='hist', bins=40, title='n_segments')\n",
        "  plt.gca().spines[['top', 'right',]].set_visible(False)\n",
        "  output_path_histogram = os.path.join(folderPath, f\"histogram_{cityName}.png\")\n",
        "  plt.savefig(output_path_histogram, dpi=300, bbox_inches=\"tight\")\n",
        "  print(f\"Histogram for {cityName} saved to {output_path_histogram}\")\n",
        "  plt.clf() # clear existing plot and make space for a new one"
      ],
      "metadata": {
        "id": "3PHRo9z2-q_m"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load shp file with all the polygons\n",
        "all_pol = gpd.read_file(\"/content/drive/MyDrive/spatialanalysis/all_pol_names/all_pol_names.shp\")\n",
        "\n",
        "base_folder = \"output_polygons\"\n",
        "os.makedirs(base_folder, exist_ok=True)  # Create base folder if it doesn't exist\n",
        "\n",
        "# Iterate through each polygon and create a new GeoDataFrame\n",
        "for index, row in all_pol.iterrows():\n",
        "\n",
        "    # Create a new GeoDataFrame for the current polygon\n",
        "    new_gdf = gpd.GeoDataFrame(\n",
        "        [row],\n",
        "        columns=all_pol.columns,\n",
        "        crs=all_pol.crs  # Retain the original CRS\n",
        "    )\n",
        "    polygon = new_gdf.geometry.iloc[0]  # Extract the Polygon/MultiPolygon geometry\n",
        "    city_name = row['name']  # Extract the city name from the row\n",
        "\n",
        "    # Define the folder name for the current polygon\n",
        "    polygon_folder = os.path.join(base_folder, f\"{city_name}\")\n",
        "\n",
        "    # Save or process the new GeoDataFrame\n",
        "    print(f\"New GeoDataFrame for {city_name} is loaded\")\n",
        "    if city_name == \"Jakarta\":\n",
        "      next\n",
        "    else:\n",
        "      os.makedirs(polygon_folder, exist_ok=True)  # Create folder if it doesn't exist\n",
        "      naturalCities(polygon,polygon_folder,city_name)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JuCM8eBTNlhO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62ec1745-75d1-4ee7-dc44-d58eca82e3ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "New GeoDataFrame for Surabaya is loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/momepy/coins.py:103: UserWarning: Lines are between points dict_keys([(691918.4661335435, 9189330.531313427), (691915.6479395456, 9189324.204884572)]) identical. Please revise input data to ensure no lines are identical or overlapping. You can check for duplicates using `gdf.geometry.duplicated()`. Assumingan angle of 0 degrees.\n",
            "  self._best_link()\n",
            "<ipython-input-2-2cb7112310f8>:38: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  city_stroke_gdf.to_file(shapefile_path)\n",
            "/usr/local/lib/python3.10/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'stroke_group' to 'stroke_gro'\n",
            "  ogr_write(\n",
            "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating best minimal value for power law fit\n",
            "xmin progress: 00%\rxmin progress: 01%\rxmin progress: 02%\rxmin progress: 03%\rxmin progress: 05%\rxmin progress: 06%\rxmin progress: 07%\rxmin progress: 08%\rxmin progress: 10%\rxmin progress: 11%\rxmin progress: 12%\rxmin progress: 13%\rxmin progress: 15%\rxmin progress: 16%\rxmin progress: 17%\rxmin progress: 18%\rxmin progress: 20%\rxmin progress: 21%\rxmin progress: 22%\rxmin progress: 23%\rxmin progress: 25%\rxmin progress: 26%\rxmin progress: 27%\rxmin progress: 28%\rxmin progress: 30%\rxmin progress: 31%\rxmin progress: 32%\rxmin progress: 33%\rxmin progress: 35%\rxmin progress: 36%\rxmin progress: 37%\rxmin progress: 38%\rxmin progress: 40%\rxmin progress: 41%\rxmin progress: 42%\rxmin progress: 43%\rxmin progress: 45%\rxmin progress: 46%\rxmin progress: 47%\rxmin progress: 48%\rxmin progress: 50%\rxmin progress: 51%\rxmin progress: 52%\rxmin progress: 53%\rxmin progress: 55%\rxmin progress: 56%\rxmin progress: 57%\rxmin progress: 58%\rxmin progress: 60%\rxmin progress: 61%\rxmin progress: 62%\rxmin progress: 63%\rxmin progress: 65%\rxmin progress: 66%\rxmin progress: 67%\rxmin progress: 68%\rxmin progress: 70%\rxmin progress: 71%\rxmin progress: 72%\rxmin progress: 73%\rxmin progress: 75%\rxmin progress: 76%\rxmin progress: 77%\rxmin progress: 78%\rxmin progress: 80%\rxmin progress: 81%\rxmin progress: 82%\rxmin progress: 83%\rxmin progress: 85%\rxmin progress: 86%\rxmin progress: 87%\rxmin progress: 88%\rxmin progress: 90%\rxmin progress: 91%\rxmin progress: 92%\rxmin progress: 93%\rxmin progress: 95%\rxmin progress: 96%\rxmin progress: 97%\rxmin progress: 98%\rAlpha: 3.387511877543187\n",
            "xmin: 14.0\n",
            "p-value: 0.02890670980231891\n",
            "-----------------------\n",
            "Log-likelihood ratio (R): 78.09700663675417\n",
            "p-value for comparison: 1.7784388530496048e-09\n",
            "Plot for power fit for Surabaya saved to output_polygons/Surabaya/power_Surabaya.png\n",
            "Classifier output saved to output_polygons/Surabaya/map_classifier_output_Surabaya.txt\n",
            "HeadTailBreaks\n",
            "\n",
            "    Interval       Count\n",
            "------------------------\n",
            "[  0.00,   3.33] | 23281\n",
            "(  3.33,   7.93] |  5357\n",
            "(  7.93,  14.63] |  1650\n",
            "( 14.63,  25.32] |   504\n",
            "( 25.32,  42.58] |   135\n",
            "( 42.58,  64.00] |    40\n",
            "( 64.00,  84.00] |    15\n",
            "( 84.00,  98.91] |     6\n",
            "( 98.91, 107.60] |     3\n",
            "(107.60, 115.50] |     1\n",
            "(115.50, 123.00] |     1\n",
            "Plot for Surabaya saved to output_polygons/Surabaya/figure_Surabaya.png\n",
            "Histogram for Surabaya saved to output_polygons/Surabaya/histogram_Surabaya.png\n",
            "New GeoDataFrame for Malang is loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2cb7112310f8>:38: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  city_stroke_gdf.to_file(shapefile_path)\n",
            "/usr/local/lib/python3.10/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'stroke_group' to 'stroke_gro'\n",
            "  ogr_write(\n",
            "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating best minimal value for power law fit\n",
            "xmin progress: 00%\rxmin progress: 01%\rxmin progress: 02%\rxmin progress: 04%\rxmin progress: 05%\rxmin progress: 07%\rxmin progress: 08%\rxmin progress: 10%\rxmin progress: 11%\rxmin progress: 13%\rxmin progress: 14%\rxmin progress: 16%\rxmin progress: 17%\rxmin progress: 19%\rxmin progress: 20%\rxmin progress: 22%\rxmin progress: 23%\rxmin progress: 25%\rxmin progress: 26%\rxmin progress: 27%\rxmin progress: 29%\rxmin progress: 30%\rxmin progress: 32%\rxmin progress: 33%\rxmin progress: 35%\rxmin progress: 36%\rxmin progress: 38%\rxmin progress: 39%\rxmin progress: 41%\rxmin progress: 42%\rxmin progress: 44%\rxmin progress: 45%\rxmin progress: 47%\rxmin progress: 48%\rxmin progress: 50%\rxmin progress: 51%\rxmin progress: 52%\rxmin progress: 54%\rxmin progress: 55%\rxmin progress: 57%\rxmin progress: 58%\rxmin progress: 60%\rxmin progress: 61%\rxmin progress: 63%\rxmin progress: 64%\rxmin progress: 66%\rxmin progress: 67%\rxmin progress: 69%\rxmin progress: 70%\rxmin progress: 72%\rxmin progress: 73%\rxmin progress: 75%\rxmin progress: 76%\rxmin progress: 77%\rxmin progress: 79%\rxmin progress: 80%\rxmin progress: 82%\rxmin progress: 83%\rxmin progress: 85%\rxmin progress: 86%\rxmin progress: 88%\rxmin progress: 89%\rxmin progress: 91%\rxmin progress: 92%\rxmin progress: 94%\rxmin progress: 95%\rxmin progress: 97%\rxmin progress: 98%\rAlpha: 3.0235428511869524\n",
            "xmin: 13.0\n",
            "p-value: 0.033629029325999205\n",
            "-----------------------\n",
            "Log-likelihood ratio (R): 52.51727716564219\n",
            "p-value for comparison: 7.811737651566019e-07\n",
            "Plot for power fit for Malang saved to output_polygons/Malang/power_Malang.png\n",
            "Classifier output saved to output_polygons/Malang/map_classifier_output_Malang.txt\n",
            "HeadTailBreaks\n",
            "\n",
            "    Interval       Count\n",
            "------------------------\n",
            "[  0.00,   2.96] | 11360\n",
            "(  2.96,   5.95] |  3997\n",
            "(  5.95,  11.38] |  1281\n",
            "( 11.38,  23.05] |   308\n",
            "( 23.05,  45.27] |    72\n",
            "( 45.27,  76.79] |    22\n",
            "( 76.79, 112.64] |     7\n",
            "(112.64, 130.25] |     2\n",
            "(130.25, 140.50] |     1\n",
            "(140.50, 146.00] |     1\n",
            "Plot for Malang saved to output_polygons/Malang/figure_Malang.png\n",
            "Histogram for Malang saved to output_polygons/Malang/histogram_Malang.png\n",
            "New GeoDataFrame for Surakarta is loaded\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-2cb7112310f8>:38: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
            "  city_stroke_gdf.to_file(shapefile_path)\n",
            "/usr/local/lib/python3.10/dist-packages/pyogrio/raw.py:723: RuntimeWarning: Normalized/laundered field name: 'stroke_group' to 'stroke_gro'\n",
            "  ogr_write(\n",
            "Values less than or equal to 0 in data. Throwing out 0 or negative values\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating best minimal value for power law fit\n",
            "xmin progress: 00%\rxmin progress: 01%\rxmin progress: 02%\rxmin progress: 04%\rxmin progress: 05%\rxmin progress: 06%\rxmin progress: 08%\rxmin progress: 09%\rxmin progress: 10%\rxmin progress: 12%\rxmin progress: 13%\rxmin progress: 14%\rxmin progress: 16%\rxmin progress: 17%\rxmin progress: 18%\rxmin progress: 20%\rxmin progress: 21%\rxmin progress: 22%\rxmin progress: 24%\rxmin progress: 25%\rxmin progress: 26%\rxmin progress: 28%\rxmin progress: 29%\rxmin progress: 30%\rxmin progress: 32%\rxmin progress: 33%\rxmin progress: 34%\rxmin progress: 36%\rxmin progress: 37%\rxmin progress: 38%\rxmin progress: 40%\rxmin progress: 41%\rxmin progress: 42%\rxmin progress: 44%\rxmin progress: 45%\rxmin progress: 46%\rxmin progress: 48%\rxmin progress: 49%\rxmin progress: 50%\rxmin progress: 52%\rxmin progress: 53%\rxmin progress: 54%\rxmin progress: 56%\rxmin progress: 57%\rxmin progress: 58%\rxmin progress: 60%\rxmin progress: 61%\rxmin progress: 62%\rxmin progress: 64%\rxmin progress: 65%\rxmin progress: 66%\rxmin progress: 68%\rxmin progress: 69%\rxmin progress: 70%\rxmin progress: 72%\rxmin progress: 73%\rxmin progress: 74%\rxmin progress: 76%\rxmin progress: 77%\rxmin progress: 78%\rxmin progress: 80%\rxmin progress: 81%\rxmin progress: 82%\rxmin progress: 84%\rxmin progress: 85%\rxmin progress: 86%\rxmin progress: 88%\rxmin progress: 89%\rxmin progress: 90%\rxmin progress: 92%\rxmin progress: 93%\rxmin progress: 94%\rxmin progress: 96%\rxmin progress: 97%\rxmin progress: 98%\rAlpha: 3.2338219778101673\n",
            "xmin: 13.0\n",
            "p-value: 0.03294296162824617\n",
            "-----------------------\n",
            "Log-likelihood ratio (R): 91.80962074153904\n",
            "p-value for comparison: 4.0922609340833815e-07\n",
            "Plot for power fit for Surakarta saved to output_polygons/Surakarta/power_Surakarta.png\n",
            "Classifier output saved to output_polygons/Surakarta/map_classifier_output_Surakarta.txt\n",
            "HeadTailBreaks\n",
            "\n",
            "    Interval       Count\n",
            "------------------------\n",
            "[  0.00,   3.46] | 16997\n",
            "(  3.46,   8.23] |  4438\n",
            "(  8.23,  16.48] |  1142\n",
            "( 16.48,  29.89] |   299\n",
            "( 29.89,  48.65] |    94\n",
            "( 48.65,  73.98] |    31\n",
            "( 73.98, 102.88] |    12\n",
            "(102.88, 156.00] |     2\n",
            "(156.00, 167.67] |     2\n",
            "(167.67, 174.00] |     1\n",
            "Plot for Surakarta saved to output_polygons/Surakarta/figure_Surakarta.png\n",
            "Histogram for Surakarta saved to output_polygons/Surakarta/histogram_Surakarta.png\n",
            "New GeoDataFrame for Yogyakarta is loaded\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b86faf8470c3>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create folder if it doesn't exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m       \u001b[0mnaturalCities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolygon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpolygon_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcity_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-2cb7112310f8>\u001b[0m in \u001b[0;36mnaturalCities\u001b[0;34m(currentCity, folderPath, cityName)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;31m# This will pull OSM data from inside the polygon and create a networkX graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   graph = ox.graph_from_polygon(\n\u001b[0m\u001b[1;32m      6\u001b[0m       \u001b[0mcurrentCity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mnetwork_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drive'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Choose network type (e.g., 'drive', 'walk', 'bike', etc.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/osmnx/graph.py\u001b[0m in \u001b[0;36mgraph_from_polygon\u001b[0;34m(polygon, network_type, simplify, retain_all, truncate_by_edge, custom_filter)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;31m# create buffered graph from the downloaded data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m     \u001b[0mbidirectional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional_network_types\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     \u001b[0mG_buff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_jsons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m     \u001b[0;31m# truncate buffered graph to the buffered polygon and retain_all for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/osmnx/graph.py\u001b[0m in \u001b[0;36m_create_graph\u001b[0;34m(response_jsons, bidirectional)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m     \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m     \u001b[0m_add_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Created graph with {len(G):,} nodes and {len(G.edges):,} edges\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/osmnx/graph.py\u001b[0m in \u001b[0;36m_add_paths\u001b[0;34m(G, paths, bidirectional)\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# add all the edge tuples and give them the path's tag:value attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reversed\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m         \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;31m# if the path is NOT one-way, reverse direction of each edge and add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/multigraph.py\u001b[0m in \u001b[0;36madd_edges_from\u001b[0;34m(self, ebunch_to_add, **attr)\u001b[0m\n\u001b[1;32m    616\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m  \u001b[0;31m# ne == 3 with 3rd value not dict, must be a key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0mkeylist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/networkx/classes/multidigraph.py\u001b[0m in \u001b[0;36madd_edge\u001b[0;34m(self, u_for_edge, v_for_edge, key, **attr)\u001b[0m\n\u001b[1;32m    506\u001b[0m             \u001b[0mdatadict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0mdatadict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m             \u001b[0mkeydict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_key_dict_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m             \u001b[0mkeydict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatadict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_succ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeydict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip files for download\n",
        "\n",
        "!zip -r /content/output_polygons.zip /content/output_polygons"
      ],
      "metadata": {
        "id": "asD-ez-uRg0Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}