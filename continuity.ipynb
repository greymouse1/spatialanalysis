{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNJPfl2ku7GmRJ+mCsv/yE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/greymouse1/spatialanalysis/blob/main/continuity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code is licenced under MIT licence.\n",
        "\n",
        "Author: Nikola G.\n",
        "\n",
        "Credits:\n",
        "\n",
        "Tutorial from Momepy package website at http://docs.momepy.org/en/stable/user_guide/graph/coins.html\n",
        "based on paper by Tripathy et al. (2020)\n",
        "\n",
        "OpenAI. (2024). ChatGPT (version 4) [Large language model]. OpenAI. https://openai.com/chatgpt\n",
        "\n",
        "\n",
        "\n",
        "Tripathy, P., Rao, P., Balakrishnan, K., & Malladi, T. (2020). An open-source tool to extract natural continuity and hierarchy of urban street networks. Environment and Planning B: Urban Analytics and City Science. http://dx.doi.org/10.1177/2399808320967680\n",
        "\n",
        "Guo, Z. (n.d.). Tutorial for generating natural streets and analyzing their scaling structure. Faculty of Engineering and Sustainable Development, Division of GIScience, University of GÃ¤vle. Retrieved from https://livablecitylab.hkust-gz.edu.cn/binjiang/Axwoman/TutorialNaturalStreets14.pdf\n"
      ],
      "metadata": {
        "id": "D9-uae52ZshA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Gs0eOwbHEqN"
      },
      "outputs": [],
      "source": [
        "!pip install osmnx > /dev/null 2>&1\n",
        "!pip install momepy > /dev/null 2>&1\n",
        "!pip install mapclassify>=2.4.0 > /dev/null 2>&1 # install mapclassify with version >=2.4.0\n",
        "!pip install powerlaw > /dev/null 2>&1\n",
        "import osmnx as ox\n",
        "import geopandas as gpd\n",
        "import momepy\n",
        "import mapclassify\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import powerlaw\n",
        "from collections import defaultdict, Counter\n",
        "from shapely.geometry import MultiLineString, LineString, Point"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load shp file with city polygon boundary (WGS84)\n",
        "\n",
        "bandung_pol = gpd.read_file(\"/content/bandung_pol/bandung_pol.shp\").geometry.iloc[0]"
      ],
      "metadata": {
        "id": "p8lF9pPu-L7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the graph within the polygon's boundaries\n",
        "# This will pull OSM data from inside the polygon and create a networkX graph\n",
        "\n",
        "graph = ox.graph_from_polygon(\n",
        "    bandung_pol,\n",
        "    network_type='drive',  # Choose network type (e.g., 'drive', 'walk', 'bike', etc.)\n",
        "    simplify=True,         # Simplify graph (remove unnecessary nodes)\n",
        "    retain_all=False,      # Keep only the largest connected component\n",
        "    truncate_by_edge=False  # Truncate by edge to keep nodes near the edge\n",
        ")\n"
      ],
      "metadata": {
        "id": "3PHRo9z2-q_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reproject graph\n",
        "# Choice of final projection is automatic, original must be WGS84\n",
        "\n",
        "bandung_streets = ox.projection.project_graph(graph)"
      ],
      "metadata": {
        "id": "IJfVAg8F_8-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create gdf from graph so it can be used later on\n",
        "\n",
        "bandung_gdf = ox.graph_to_gdfs(\n",
        "    ox.convert.to_undirected(bandung_streets),\n",
        "    nodes=False,\n",
        "    edges=True,\n",
        "    node_geometry=False,\n",
        "    fill_edge_geometry=True,\n",
        ")"
      ],
      "metadata": {
        "id": "bhuPU7z9Anc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot downloaded OSM roads\n",
        "\n",
        "bandung_gdf.plot(figsize=(10, 10), linewidth=0.2).set_axis_off()"
      ],
      "metadata": {
        "id": "UMa2nquqA0_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate continuity from the gdf\n",
        "\n",
        "continuity = momepy.COINS(bandung_gdf, angle_threshold=135, flow_mode=False)"
      ],
      "metadata": {
        "id": "Lc4SakEXKbOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull out stroke\n",
        "\n",
        "bandung_stroke_gdf = continuity.stroke_gdf()"
      ],
      "metadata": {
        "id": "OUy7tp1uK6K7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vertex-to-linestring mapping\n",
        "vertex_to_linestring = defaultdict(list)\n",
        "\n",
        "# Iterate over geometries and map vertices to LineStrings (handle MultiLineString)\n",
        "for idx, geom in bandung_stroke_gdf.geometry.items():\n",
        "    if isinstance(geom, LineString):  # Process single LineString\n",
        "        for point in geom.coords:\n",
        "            vertex_to_linestring[Point(point)].append(idx)\n",
        "    elif isinstance(geom, MultiLineString):  # Process MultiLineString\n",
        "        # For each LineString in MultiLineString\n",
        "        for subline in geom.geoms:\n",
        "            for point in subline.coords:\n",
        "                vertex_to_linestring[Point(point)].append(idx)\n",
        "\n",
        "# Initialize a dictionary to store the connection counts for each line\n",
        "line_connections = defaultdict(int)\n",
        "\n",
        "# Iterate over the geometries again to count connections\n",
        "for idx, geom in bandung_stroke_gdf.geometry.items():\n",
        "    if isinstance(geom, LineString):  # Process single LineString\n",
        "        connections = []  # Use a list to count multiple connections\n",
        "        for point in geom.coords:\n",
        "            for connected_line in vertex_to_linestring[Point(point)]:\n",
        "                if connected_line != idx:\n",
        "                    connections.append(connected_line)  # Add connection to the list\n",
        "        line_connections[idx] = len(connections)  # Store the total number of connections\n",
        "    elif isinstance(geom, MultiLineString):  # Process MultiLineString\n",
        "        # For each LineString in MultiLineString\n",
        "        for subline in geom.geoms:\n",
        "            connections = []  # Use a list to count multiple connections for each subline\n",
        "            for point in subline.coords:\n",
        "                for connected_line in vertex_to_linestring[Point(point)]:\n",
        "                    if connected_line != idx:\n",
        "                        connections.append(connected_line)  # Add connection to the list\n",
        "            # Store the connection count for each subline (if necessary)\n",
        "            # For now, we store the count for the entire MultiLineString\n",
        "            line_connections[idx] = len(connections)\n",
        "\n",
        "\n",
        "# Extract degree (number of connections) values\n",
        "degree_values = list(line_connections.values())\n",
        "\n",
        "# Count frequencies of degree values\n",
        "degree_counts = Counter(degree_values)\n",
        "\n",
        "# Extract x (degrees) and y (frequencies)\n",
        "x = np.array(list(degree_counts.keys()))       # Unique degree values\n",
        "y = np.array(list(degree_counts.values()))    # Frequency of each degree\n",
        "\n",
        "# Fit the degree distribution to a power-law model\n",
        "fit = powerlaw.Fit(degree_values)\n",
        "print(f\"Alpha: {fit.alpha}\")\n",
        "print(f\"xmin: {fit.xmin}\")\n",
        "\n",
        "# Get alpha and xmin (scaling parameter and lower bound for the power-law fit)\n",
        "alpha = fit.alpha\n",
        "xmin = fit.xmin\n",
        "\n",
        "# Get the p-value from the goodness-of-fit test\n",
        "p_value = fit.power_law.KS()\n",
        "\n",
        "print(f\"p-value: {p_value}\")\n",
        "print(\"-----------------------\")\n",
        "# Compare the power-law fit with an alternative distribution (e.g., exponential)\n",
        "R, p_alt = fit.distribution_compare('power_law', 'exponential')\n",
        "print(f\"Log-likelihood ratio (R): {R}\")\n",
        "print(f\"p-value for comparison: {p_alt}\")\n",
        "\n",
        "# Plot the data and the fitted power law\n",
        "fig = fit.plot_pdf(marker='o', color='blue', markersize=4, label='Empirical Data')\n",
        "fit.power_law.plot_pdf(ax=fig, color='red', linestyle='--', linewidth=1, label='Power Law Fit')\n",
        "\n",
        "# Add legend and labels\n",
        "plt.xlabel(\"Degree (Connections)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wrMnvfU8atNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add connections to original gdf\n",
        "bandung_stroke_gdf['n_connections'] = degree_values\n",
        "\n",
        "# Calculate heavy tailed classification\n",
        "classifier = mapclassify.HeadTailBreaks(degree_values)\n",
        "\n",
        "# Show the classifier (lower and upper bounds plus count)\n",
        "print(classifier)\n",
        "\n",
        "# Plot natural streets\n",
        "bandung_stroke_gdf.plot(\n",
        "    figsize=(15, 15),\n",
        "    cmap=\"viridis_r\",\n",
        "    column=\"n_connections\", # uses number of connection per segment(individual segments are determined with COINS)\n",
        "    legend=True,\n",
        "    linewidth=0.3,\n",
        "    scheme=\"headtailbreaks\", # break n_connections by head/tails\n",
        ").set_axis_off()"
      ],
      "metadata": {
        "id": "RzzbBMKb_sEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Histogram for n_segments\n",
        "\n",
        "bandung_stroke_gdf['n_connections'].plot(kind='hist', bins=40, title='n_segments')\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "metadata": {
        "id": "Ei7uRHqI85bA"
      }
    }
  ]
}